Day 1:
Docker Basic Commands
=====================

Basic
: docker version
: docker -v 
: docker --version 
: docker info
: docker --help
: docker login

————————————
Images
: docker images                        To list the images
: docker images -q                     To list the images
: docker pull                          To pull tha image
: docker rmi                           To remove one or more iamges
: docker rmi $(docker images -q)       To remove all images

————————————
Containers
: docker ps                                                 shows only running cotainers(use -a for show all containers))
: docker ps -a                                              shows all containers
: docker rm <container-name>  
docker rm 4f8f3a386b78    
docker rmi  5d0da3dc9764                          remove one or more containers
: docker rm $(docker ps -a -q)  
docker rmi image id/image name

docker rmi $(docker ps -a -q)                             remove all containers

docker rmi -f $(docker ps -a -q)   			force removed 
: docker run <image-name>                                   create a container from image (first time used to container)
: docker run -d <image-name>                                create a container from image in detached mode
: docker run -it <image-name> bash                          create a container from image in interactive mode
: docker start -i <container-name>                          To start the stoped container
: docker stop <container-name>                              To stop running container
: docker logs <container-name>                              To sess logs of contianer
: docker exec -it <container-name> bash                     To interact with container

: docker run --name a-centos -it centos bash                container will not be removed on exit, if image is not present it will pull the image and create container.
docker start -i a-centos
: docker run --name b-centos --rm -it centos bash           container will be removed on exit
  
docker login   -=credentials of docker hub, required to push docker images to docker hub repos


Day 2:
===>Docker Architecture: Docker has the following Components:
(1)Docker Engine
(2)Docker Client
(3)Docker Registries
(4)Docker Objects

(1)Docker Engine
- core part of the whole Docker system
- It is a client-server application with these major components:
(1.1)Server: It is the docker daemon called dockerd. It can create and manage docker images. Containers, networks, etc.
(1.2)Rest API: It is used to instruct docker daemon what to do.
(1.3)Command Line Interface (CLI): It is a client which is used to enter docker commands.

(2)Docker Client
- Docker users can interact with Docker through a client. 
- When any docker commands runs, the client sends them to dockerd daemon, which carries them out. Docker API is used by Docker commands. Docker client can communicate with more than one daemon.

(3)Docker Registries
- It is the location where the Docker images are stored. It can be a public docker registry or a private docker registry. 
- Docker Hub is the default place of docker images, its stores’ public registry. 
- When you execute docker pull or docker run commands, the required docker image is pulled from the configured registry. 
- When you execute docker push command, the docker image is stored on the configured registry.
-Docker store allows you to buy and sell Docker images or distribute them for free.

===>Docker Environment :Combination of Docker Engine and Docker Objects

(4)Docker Objects
- When you are working with Docker, you use images, containers, volumes, networks; all these are Docker objects.


===>Docker Objects

(1)Images
- Docker images are read-only templates with instructions to create a docker container. 
- Docker image can be pulled from a Docker hub and used as it is, or you can add additional instructions to the base image and create a new and modified docker image. 
- You can create your own docker images also using a dockerfile. Create a dockerfile with all the instructions to create a container and run it; it will create your custom docker image.
- Docker image has a base layer which is read-only, and the top layer can be written. When you edit a dockerfile and rebuild it, only the modified part is rebuilt in the top layer.

(2)Containers
- After you run a docker image, it creates a docker container. 
- All the applications and their environment run inside this container. You can use Docker API or CLI to start, stop, delete a docker container.
- E.g:Basic Hello World
docker container run hello-world
or
docker run hello-world

-->To run a ubuntu docker container: docker run -i -t ubuntu /bin/bash

(3)Volumes
- The persisting data generated by docker and used by Docker containers are stored in Volumes. They are completely managed by docker through docker CLI or Docker API. 
- Volumes work on both Windows and Linux containers. Rather than persisting data in a container’s writable layer, it is always a good option to use volumes for it. 
- Volume’s content exists outside the lifecycle of a container, so using volume does not increase the size of a container.
- You can use -v or –mount flag to start a container with a volume. 
- E.g :In this sample command, you are using xvolume volume with xxx container.

docker run -d --name xxx  -v xvolume:/app nginx:latest

(4)
s
-Docker networking is a passage through which all the isolated container communicate. 
-There are mainly five network drivers in docker:
(4.1)Bridge: It is the default network driver for a container. You use this network when your application is running on standalone containers, i.e. multiple containers communicating with same docker host.
(4.2)Host: This driver removes the network isolation between docker containers and docker host. It is used when you don’t need any network isolation between host and container.
(4.3)Overlay: This network enables swarm services to communicate with each other. It is used when the containers are running on different Docker hosts or when swarm services are formed by multiple applications.
(4.4)None: This driver disables all the networking.

---->Registry & Repository
-A repository is a hosted collection of tagged images that together create the file system for a container.

-A registry is a host -- a server that stores repositories and provides an HTTP API for managing the uploading and downloading of repositories.
-Docker.com hosts its own index to a central registry which contains a large number of repositories. Having said that, the central docker registry does not do a good job of verifying images and should be avoided if you're worried about security.

https://hub.docker.com/r/pradeepch82/spring-boot-cms/tags?page=1&ordering=last_updated
docker pull pradeepch82/spring-boot-cms:latest
docker images
docker run  -- name p-spring -d pradeepch82/spring-boot-cms

docker logs p-sprimg


====================
Web Servers 
:httpd default port number 80
:nginx default port number 80

networking concept
=====================
bridge
host
none

:docker network ls
creare 2 containers 
docker run --name a-centos -it centos
docker run --name b-centos -it centos
docker ps -a
docker start a-centos
docker start b-centos
docker inspect bridge

communicate netween containers.
172.17.0.2

docker exec -it a-centos bash
docker ping 172.17.0.2(ip of b-centos)


;container in the bridge network communicatee with each other 


with the help of deafult bridge network we will not able to communicate with container name.

custom default bridge network
==============================
docker network create demo-network--default will create bridge network
docker network create demo-network 
docker run --name c-centos --network demo-network -it centos bash 
docker run --name d-centos --network demo-network -it centos bash

docker start c-centos d-centos
docker ps --shows all 4 conta
docker  network inspect demo-network--->(c,d)
docker network inspect ---->(a,b) 172.17 is default


docker exec --it c-dentos bash
ping d-centos  -->will able to communicate with ip and container name

to add existing container we use connect command, one container we can add to multiple networks.

===============
1.communicating with docker container
======================================
docker exec 

Demo 1:
MySQL container
================
$ docker run --name demo-mysql -e MYSQL_ROOT_PASSWORD=manisha -d mysql
-e:enviroment
-d:detached mode

check th logs
docker logs demo-mysql
docker ps :will show mysql started on port no 3306 , we can not access it as it is in default network . we can not access it outside of the network.

docker exec -it demo-mysql bash 
mysql -uroot -pmanisha 

Demo 2:MongoDB container
--->Downloading the Latest MongoDB Docker Image
docker pull mongo #Pulls the latest one
or 
docker pull mongo:4.0.4 #Pulls the specific version

--->Deploying an Instance of MongoDB as a Container
docker run --name mongodb mongo:4.0.4

--> To check out on the logs for the image
docker logs mongodb
(Displays entire information of the container while starting as well the confirguration details if it has started successfully)
-->docker start mongodb

--->Interacting with the MongoDB Docker Container with Basic Shell Operations
docker exec -it mongodb bash

-it: stands for interactive mode

--> To communication with mongodb
Example: mongo

--> Show databases
show dbs;

--> To create a database
use trainingdb;

--> Switch to database
trainingdb

--> To create a collection
db.departments.insert({name:'Admin'});
db.departments.insert({name:'Training'});
db.departments.insert({name:'Quality'});
db.departments.insert({name:'HR'});

-->Fetch the data
db.departments.find()

Demo 3:
command to create tomcat container.
docker run --name a-tomcat -p 1212:8080 -d tomcat
docker start a-tomcat bash
cd conf


2. port forwardization
=======================
httpd:80,nginx:80 
mysql:3306
mongodb:27017

All containers are created with in the default network ,outer rectangle is docker host where docker engine installed. containers will not be available outside the network to access them externally we do port forwardization.


============================
======================================
we can create multiple containers in one go with docker compose 

docker  inspect network bride: will show mysql 
create containers for webserver
web servers :httpd    default port :80
            :nginx    default port :80
            :mysql    default port :3306
            :mongodb  default port :27017   

Demo1 with Sandbox

docker run --name a-nginx -p  1111:80 -d nginx
docker run --name b-nginx -p  2222:80 -d nginx
docker run --name c-nginx -p  3333:80 -d nginx
-p:port forwardization 
internal port is 80 but we are exposing container on 1111
docker ps --- all containers are exposed to external port numbers.

docker exec -it a-nginx bash
echo "<h1>Hello A-NgInx Server </h1>" > /usr/share/nginx/html/index.html

docker exec -it b-nginx bash
echo "<h1>Hello B-NgInx Server </h1>" > /usr/share/nginx/html/index.html

docker exec -it c-nginx bash
echo "<h1>Hello C-NgInx Server </h1>" > /usr/share/nginx/html/index.html

Demo2: Docker desktop /toolbox
localhost:1111
localhost:2222



=======================================================
-- rm will remove the container after exit , doesnt work in -d mode

docker run --it --rm tomcat:9.0-- will 
docker run --rm --name b-tomcat -p 1111:8080 -it  tomcat:9.0 bash
exit
docker ps -a -- will not show b-tomcat
-------------------------------------------------------


3. Image creation 
Images (Documentation: https://docs.docker.com/engine/reference/commandline/docker/)

--->Lists the images available locally
docker images 
or
docker image list
or
docker image ls

Notes:
- The TAG refers to a particular snapshot of the image 
- IMAGE ID is the corresponding unique identifier for that image.
- you can think of an image akin to a git repository
--->Where are Images Stored
(1) Registries (e.g. docker hub)
(2) Can be stored locally or remote

--->Pulling an image from the repository
docker pull ubuntu
docker pull ubuntu:18.04 

Notes:
- images can be committed with changes and have multiple versions.If you don't provide a specific version number, the client defaults to latest

Example: Commiting the Image in the container (mongodb)
--------------------------------------------
--->Downloading the Latest MongoDB Docker Image
docker pull mongo #Pulls the latest one
or 
docker pull mongo:4.0.4 #Pulls the specific version

--->Deploying an Instance of MongoDB as a Container
docker run --name mongodb mongo:4.0.4

--> To check out on the logs for the image
docker logs mongodb
(Displays entire information of the container while starting as well the confirguration details if it has started successfully)
-->docker start mongodb

--->Interacting with the MongoDB Docker Container with Basic Shell Operations
docker exec -it mongodb bash

-it: stands for interactive mode

--> To communication with mongodb
Example: mongo

--> Show databases
show dbs;

--> To create a database
use trainingdb;

--> Switch to database
trainingdb

--> To create a collection
db.departments.insert({name:'Admin'});
db.departments.insert({name:'Training'});
db.departments.insert({name:'Quality'});
db.departments.insert({name:'HR'});

-->Fetch the data
db.departments.find()

Creating Custom Images:
================================
standar images are available on docker h
ubuntu
https
tomcat
mongodb

 Day 4:
we can create custom images in 2  ways
1. Creating image  from running container  (docker commit command)
========================================
docker rmi $(docker images -q)
Step 1: create a container
docker run --name a-httpd -p 1111:80 -d httpd :create httpd container

step 2:change the contents of html file
docker exec -it a-https bash :exec container ls :check htdocs folder with ls command
echo "<h1>Hello Welcome To Custom Apache Image</h1>" > /usr/local/apache2/htdocs/index.html:change index.html 

step 3: commit the changes
docker commit -m 'Modified Index Page' -a 'Manisha Mane <manisha.mane@atos.net>' a-httpd manishaato/httpdApachImage1:1.1

-m:commit msg
-a: author
<docker hub id>/<ImageName>:version(optional)

http
step 4:Push image to docker hub

docker login
username:manishaatoa
password:

docker push httpdApachImage1:1.1



2.Creating image  from scratch(docker build command)

for this we use Dockerfile : 
A text file with instructions to build image
Automation of Docker Image Creation
we need Base Image
Docker File (Instructions used for Image creation)
===========
FROM           :Base Image    
MAINTAINER     :Author Name
ENV            :Environment variable
ADD            :ADD the files while buiding the image
RUN            :To install libraries/packages (executed while building the image) aptupdate,apt-getupdate
ENTRYPOINT     :Executed at run time and we can not override the commands
CMD            :Executed at run time and we can override by passing command line argument

whenever we start/create container which command to execute we specify with entrypoint and CMD
CMD echo "Hello"
ENTRYPOINT ["echo","hello"]

Step 1 : Create a file named Dockerfile
Step 2 : Add instructions in Dockerfile
Step 3 : Build dockerfile to create image
Step 4 : Run image to create container

Exanple:Dockerfile
Step 1 : Create a file named Dockerfile

$vi Dockerfile

Step 2 : Add instructions in Dockerfile
copy the below code

FROM ubuntu
MAINTAINER Manisha Mane <pimplemp@rediffmail.com>
RUN apt-get update

CMD ["echo", "Hello World..! from my first docker iamge1"]


CMD ["echo", "Hello World..! from my first docker iamge2"]
CMD ["echo", "Hello World..! from my first docker iamge3"]
CMD ["echo", "Hello World..! from my first docker iamge4"]

Note: CMD can be written multiple times but the last one will be called
Step 3 : Build dockerfile to create image
$ docker build -t manishaatos/a-ubuntu:1.1 .(current directory)
-t --taging name to Image 

here -t is for tagging image
dot is for the current dir where Dockerfile is created
You may createmultiple images from the dockerfile

$ docker build -t b-ubuntu:1.1 .

step 4: you can optionally push the image to docker hub
docker push  manishaatos/a-ubuntu:1.1

step 5:
docker run --name c1 manishaatos/a-ubuntu:1.1

Using ENTRYPOINT
modify the Dockerfile as below

FROM ubuntu
MAINTAINER Chhaya Nikam <chhaya.nikam@gmail.com>
RUN apt-get update

ENTRYPOINT ["echo", "Hello World..! from my first docker iamge1"]
ENTRYPOINT ["echo", "Hello World..! from my first docker iamge2"]
ENTRYPOINT ["echo", "Hello World..! from my first docker iamge3"]
ENTRYPOINT ["echo", "Hello World..! from my first docker iamge4"]

The main difference between CMD and ENTRYPOINT is ENTRYPOINT  allows appending new contents while running docker container

$ docker build -t testentry .
// optionally if dockerfile name is different give any other filename
$ docker build -f Somefile -t testentry1 .

$ docker run testentry1
$ docker run c echo "Hello friends"

Using ENTRYPOINT
modify the Dockerfile as below

FROM ubuntu
MAINTAINER Chhaya Nikam <chhaya.nikam@gmail.com>
RUN apt-get update

ENTRYPOINT ["echo", "Hello World..! from my first docker iamge1"]
ENTRYPOINT ["echo", "Hello World..! from my first docker iamge2"]
ENTRYPOINT ["echo", "Hello World..! from my first docker iamge3"]
ENTRYPOINT ["echo", "Hello World..! from my first docker iamge4"]

The main difference between CMD and ENTRYPOINT is ENTRYPOINT  allows appending new contents while running docker container

$ docker build -t testentry .
// optionally if dockerfile name is different give any other filename
$ docker build -f Somefile -t testentry1 .

$ docker run testentry1
$ docker run c echo "Hello friends"

CMD and ENTRYPOINT can also used in combinations

Example:

Docker file for MYSQL
=======================


Step 1: vi script.sql
script.sql
===========
use company;
create table employee(id int primary key,name text,salary double);
insert into employee values(101,'RAM',10000.00);
insert into employee values(102,'RAHIM',20000.00);
insert into employee values(103,'DAVID',30000.00);
insert into employee values(104,'Jack',40000.00);

Step 2:
vi Dockerfile
# Derived from official mysql image (our base image)
FROM mysql
# Add a database
ENV MYSQL_DATABASE company
ENV MYSQL_ROOT_PASSWORD admin
ENV MYSQL_USER user1
ENV MYSQL_PASSWORD password
# Add the content of the sql-scripts/ directory to your image
# All scripts in docker-entrypoint-initdb.d/ are automatically
# executed during container startup
ADD script.sql /docker-entrypoint-initdb.d/

$ docker build -t p-mysql:5.1 .
$ docker images
$docker run --name a-mysql -d p-mysql:5.1
$docker exec -it a-mysql bash
#mysql -uroot -padmin






Docker Compose (start ,stop,scale multiple containers at same time )
=============================================================
docker-compose :utility
docker-compose -v
Docker compose

It is a utility tool for defining & running multi-container docker applications
use yaml files to configure application services (docker-compose.yml)
can start all services with a single command : docker-compose up
can stop all services with a single command : docker-compose down
can scale up selected services when required


Step 1 : install docker compose
   (already installed on windows and mac with docker)
   docker-compose -v

   2 Ways

   1.  https://github.com/docker/compose/rel...

   2. Using PIP
    pip install -U docker-compose

Step 2 : Create docker compose file at any location on your system
   docker-compose.yaml

version: '3'
services:
  web:
    image: nginx
  database:
    image: redis


Step 3 : Check the validity of file by command
    docker-compose config  :check syntax of yaml file.


docker network ls
there is no "root_default" now execute the below it should create this network

Step 4 : Run docker-compose.yml file by command
   docker-compose up -d
$docker ps
$docker inspect network root_default

so docker-compose internally creates a custom bridge network.
 Note :
Steps 5 : Bring down application by command
 $  docker-compose down
 $docker inspect network root-default

TIPS
How to scale services

scale
docker-compose up -d --scale database=4

docker-compose up -d --scale web=4


Day 5:
Container linking 

volumn



Container linking
=================	
workpress is a web application which internally communicate with mysql.
communicating between containers
Linking Docker containers with Links
===========================================
--today
example: wordpress+mysql linking

Links allow the containers to discover each other and securely transfer the information about one container to 

another container.

step 1: create a custom bridge network
docker network create p-network

verify: 
docker network ls

step 2:
docker run --name mysql02 --network p-network -e MYSQL_ROOT_PASSWORD=Password1234 -d mysql:5.6
verify: 
docker ps
docker images
docker inspect p-network

step 3:
docker run --name wordpress03 --network p-network --link mysql02 -p 2222:80 -e WORDPRESS_DB_HOST=mysql02:3306 

-e WORDPRESS_DB_USER=root -e WORDPRESS_DB_PASSWORD=Password1234 -e WORDPRESS_DB_NAME=wordpress -e 

WORDPRESS_TABLE_PREFIX=wp_ -d wordpress

Note:It is added to same p-network , --link is used to link the container, def port 80 of mysql is exposed to 

1111,
       -e is used for environment variable.
       instead of ip address we are using mysql container name,3306 is the port at which sql server is running, 

password1234 is provided to wordpress to connect to        mysql db, wordpress database will be created with 

the table name prefixed as wp_ , both the containers will start in detach mode because of -d.
same pwd as mysql.

step 4: test
click the 1111 port
select eng language-->complete the form ---> Install wordpress. Install wordpress

Step 5:
start mysql container and check for newly created database as wordpress.

step 6:checking the tables are created in mysql. 
so lets move inside the mysql02 container.
docker exec -it mysql02 bash
mysql -uroot -pPassword1234
show databases
use wordpress;
show tables;


Note :what we create in wordpress get stored in mysql.
we are exposing only wordpress with client not mysql.
step 4: create a new post. 2 containers from 2 different network can communicate with ingress network
query the user_post table
 

exit;  ----------> comes out of the container

volumn
======
1. What are Volumes
2. How to create / list / delete volumes
3. How to attach volume to a container
4. How to share volume among containers
5. What are bind mounts

Volumes are the preferred mechanism for persisting data generated by and used by Docker containers

docker volume  //get information
docker volume create
docker volume ls
docker volume inspect
docker volume rm
docker volume prune

Use of Volumes
===================
Decoupling container from storage
Share volume (storage/data) among different containers
Attach volume to container
On deleting container volume does not delete

===>Docker Volumes:

-->The Docker File System
- In order to understand Docker volumes, it is important to first understand how the Docker file system works.
- A Docker image is a collection of read-only layers. When you launch a container from an image, Docker adds a 

read-write layer to the top of that stack of read-only layers. Docker calls this the Union File System.
- Any time a file is changed, Docker makes a copy of the file from the read-only layers up into the top read-

write layer. This leaves the original (read-only) file unchanged.
- When a container is deleted, that top read-write layer is lost. This means that any changes made after the 

container was launched are now gone.
------------------------
- The whole idea is that you can start, stop and delete the containers without losing data.So if you need to 

persist data, do it outside of the containers.
- Volumes are the preferred mechanism for persisting data generated by and used by Docker containers
- By default all files created inside a container are stored on a writable container layer
- The data doesn’t persist when that container is no longer running
- A container’s writable layer is tightly coupled to the host machine where the container is running. You can’t 

easily move the data somewhere else.
------------------------
--->How a Volume Can Help?
- A volume allows data to persist, even when a container is deleted. Volumes are also a convenient way to share 

data between the host and the container.
- Mounting a volume is a good solution if you want to:
(1)Push data to a container.
(2)Pull data from a container.
(3)Share data between containers.
- Docker volumes exist outside the Union File System of read-only and read-write layers. The volume is a folder 

which is shared between the container and the host machine. Volumes can also be shared between containers.
- From the container, the volume acts like a folder which you can use to store and retrieve data. It is simply 

a mount point to a directory on the host.
- volumes are managed by Docker and are isolated from the core functionality of the host machine
-----------------------------------------------
Step 1 — Creating an Independent Volume

-------------------
---> make a data volume called data:
docker volume create mydata

--->list of all the volumes created and their driver
docker volume ls

--->Get details of the volume
docker volume inspect mydata

--->removing volumes
docker volume rm mydata

-------------

Commands
docker run --name MyJenkins1 -v mydata:/var/jenkins_home -p 8080:8080 -p 50000:50000  -d jenkins/jenkins
docker logs MyJenkin1


docker run --name MyJenkins2 -v mydaat:/var/jenkins_home -p 9090:8080 -p 60000:50000 jenkins/jenkins

Note : only run the first command in detached mode
When you run the Jenkins second instance it will not generate the admin password . It will take the same 

password for the first one as it is stored and data is shared between volume

	

